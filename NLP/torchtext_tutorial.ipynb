{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchtext\n",
    "\n",
    "from konlpy.tag import Kkma\n",
    "from torchtext.data import Field, Iterator, Example, TabularDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.2.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchtext.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Field - 텐서 변환을 위해 데이터타입 정의\n",
    "tagger = Kkma()\n",
    "tokenize = tagger.morphs\n",
    "preprocessing = lambda x: 0 if x == \"FOOD\" else 1\n",
    "\n",
    "TEXT = Field(tokenize=tokenize, \n",
    "             use_vocab=True, \n",
    "             lower=True,\n",
    "             include_lengths=True,\n",
    "             batch_first=True,\n",
    "            )\n",
    "\n",
    "LABEL = Field(sequential=False,\n",
    "              use_vocab=False,\n",
    "              preprocessing=preprocessing,\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = TabularDataset.splits(path='./',\n",
    "                                              train='torchtext_train.txt',\n",
    "                                              test='torchtext_test.txt',\n",
    "                                              format='tsv',\n",
    "                                              fields=[('TEXT', TEXT), ('LABEL', LABEL)]\n",
    "                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['배고프', '다', '밥', '주', '어']\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(train_data.examples[0].TEXT)\n",
    "print(train_data.examples[0].LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TEXT.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function torchtext.vocab._default_unk_index>,\n",
       "            {'<pad>': 1,\n",
       "             '<unk>': 0,\n",
       "             '?': 6,\n",
       "             'ㄴ': 7,\n",
       "             '거': 8,\n",
       "             '고': 9,\n",
       "             '고등': 20,\n",
       "             '과': 21,\n",
       "             '근처': 22,\n",
       "             '기': 23,\n",
       "             '나': 24,\n",
       "             '냐': 25,\n",
       "             '는': 3,\n",
       "             '다': 10,\n",
       "             '다시': 26,\n",
       "             '드라마': 27,\n",
       "             '랩': 28,\n",
       "             '만': 29,\n",
       "             '만하': 30,\n",
       "             '맛': 31,\n",
       "             '맛있': 32,\n",
       "             '먹': 4,\n",
       "             '뭐': 11,\n",
       "             '밥': 12,\n",
       "             '배고프': 33,\n",
       "             '보': 13,\n",
       "             '보여주': 14,\n",
       "             '볼만': 34,\n",
       "             '삼겹살': 35,\n",
       "             '신': 36,\n",
       "             '싶': 15,\n",
       "             '알려주': 37,\n",
       "             '어': 2,\n",
       "             '없': 38,\n",
       "             '영상': 39,\n",
       "             '영화': 16,\n",
       "             '예능': 40,\n",
       "             '요즘': 41,\n",
       "             '을': 42,\n",
       "             '음식': 43,\n",
       "             '이': 44,\n",
       "             '있': 45,\n",
       "             '재밌': 17,\n",
       "             '점': 46,\n",
       "             '좀': 5,\n",
       "             '주': 18,\n",
       "             '줄거리': 47,\n",
       "             '지': 48,\n",
       "             '집': 49,\n",
       "             '추천': 19,\n",
       "             '푸': 50,\n",
       "             '하': 51,\n",
       "             '하이라이트': 52,\n",
       "             '함께': 53})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.stoi # defaultdict instance mapping token strings to numerical identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.vocab.itos # list of token strings indexed by their numerical identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'?': 2,\n",
       "         'ㄴ': 2,\n",
       "         '거': 2,\n",
       "         '고': 2,\n",
       "         '고등': 1,\n",
       "         '과': 1,\n",
       "         '근처': 1,\n",
       "         '기': 1,\n",
       "         '나': 1,\n",
       "         '냐': 1,\n",
       "         '는': 3,\n",
       "         '다': 2,\n",
       "         '다시': 1,\n",
       "         '드라마': 1,\n",
       "         '랩': 1,\n",
       "         '만': 1,\n",
       "         '만하': 1,\n",
       "         '맛': 1,\n",
       "         '맛있': 1,\n",
       "         '먹': 3,\n",
       "         '뭐': 2,\n",
       "         '밥': 2,\n",
       "         '배고프': 1,\n",
       "         '보': 2,\n",
       "         '보여주': 2,\n",
       "         '볼만': 1,\n",
       "         '삼겹살': 1,\n",
       "         '신': 1,\n",
       "         '싶': 2,\n",
       "         '알려주': 1,\n",
       "         '어': 8,\n",
       "         '없': 1,\n",
       "         '영상': 1,\n",
       "         '영화': 2,\n",
       "         '예능': 1,\n",
       "         '요즘': 1,\n",
       "         '을': 1,\n",
       "         '음식': 1,\n",
       "         '이': 1,\n",
       "         '있': 1,\n",
       "         '재밌': 2,\n",
       "         '점': 1,\n",
       "         '좀': 3,\n",
       "         '주': 2,\n",
       "         '줄거리': 1,\n",
       "         '지': 1,\n",
       "         '집': 1,\n",
       "         '추천': 2,\n",
       "         '푸': 1,\n",
       "         '하': 1,\n",
       "         '하이라이트': 1,\n",
       "         '함께': 1})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.freqs # Counter object holding the frequencies of tokens in the data used to build the vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterator 선언 L loads batches of data from a dataset\n",
    "# args \n",
    "#    - dataset : dataset object to load dataset\n",
    "#    - batch_size : Batch size (mini-batch)\n",
    "#    - device : -1은 CPU, None은 active GPU device\n",
    "#    - sort_key : 데이터들을 정렬하기위한 key, 비슷한 길이와 패딩최소화 된 예제를 함께 배치\n",
    "train_iter, test_iter = Iterator.splits((train_data, test_data),\n",
    "                                        batch_size=3,\n",
    "                                        device=-1,\n",
    "                                        sort_key=lambda x: len(x.TEXT),\n",
    "                                        sort_within_batch=True,\n",
    "                                        repeat=False\n",
    "                                       ) # x.TEXT 기준으로 정렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.config import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Variable containing:\n",
      "   20    28    50     2    26    13    23     5\n",
      "   35     4     9    15     2     1     1     1\n",
      "   12    18     2     1     1     1     1     1\n",
      "[torch.LongTensor of size 3x8]\n",
      ", \n",
      " 8\n",
      " 5\n",
      " 3\n",
      "[torch.LongTensor of size 3]\n",
      ")\n",
      "Variable containing:\n",
      " 1\n",
      " 0\n",
      " 0\n",
      "[torch.LongTensor of size 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for batch in train_iter:\n",
    "    print(batch.TEXT)\n",
    "    print(batch.LABEL)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbedClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, output_size):\n",
    "        super(EmbedClassifier, self).__init__()\n",
    "        \n",
    "        # 각 단어의 임베딩을 평균해서 문장 단위의 임베딩 표현\n",
    "        self.sentence_embed = nn.EmbeddingBag(vocab_size, embedding_size)\n",
    "        self.linear = nn.Linear(embedding_size, output_size)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        outputs = self.sentence_embed(inputs)\n",
    "        outputs = self.linear(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP=50\n",
    "LR=0.1\n",
    "\n",
    "model = EmbedClassifier(len(TEXT.vocab), 20, 2) \n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6451420068740845\n",
      "0.47487186789512636\n",
      "0.31591417491436\n",
      "0.18547815084457397\n",
      "0.19009195640683174\n"
     ]
    }
   ],
   "source": [
    "for step in range(STEP):\n",
    "    losses = []\n",
    "    for i, batch in enumerate(train_iter):\n",
    "        inputs, lengths = batch.TEXT\n",
    "        targets = batch.LABEL\n",
    "        model.zero_grad()\n",
    "        preds = model(inputs)\n",
    "        loss = loss_function(preds, targets)\n",
    "        losses.append(loss.data[0])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if step % 10 == 0:\n",
    "        print(np.mean(losses))\n",
    "        losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### numericalize\n",
    "\n",
    "문장 -> 인덱스에 맞는 numerical vector (LongTensor)로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n"
     ]
    }
   ],
   "source": [
    "for test in test_data.examples:\n",
    "    input, length = TEXT.numericalize(([test.TEXT,], [len(test.TEXT)]), train=False, device=-1)\n",
    "    pred = model(input)\n",
    "    pred = pred.max(1)[1]\n",
    "    print(pred.data[0], test.LABEL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
